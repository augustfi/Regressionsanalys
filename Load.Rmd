```{r Load in data}

bodyfatmen <- read.csv("/Users/augustfilannino/Documents/Regressionsanalys/bodyfatmen.csv", header = TRUE)


# str(bodyfatmen)
# head(bodyfatmen)
```

```{r Libraries}

#install.packages("car")

library(car)   # For avPlots
library(MASS)  # For studres
library(MPV)   # If needed
```

```{r Build model}
bodyfat.model <- lm(density ~ age + weight + height + neck + chest + abdomen + hip + thigh + knee + ankle + biceps + forearm + wrist, data=bodyfatmen)
```

```{r Coding Histogram and QQ-plot}
model_residuals =bodyfat.model$residuals
hist(model_residuals)
qqnorm(rstudent(bodyfat.model))
qqline(rstudent(bodyfat.model))
#Alternative plots using olsrr library
ols_plot_resid_hist(bodyfat.model)
ols_plot_resid_qq(bodyfat.model)

#there are numerous ways of testinf normality. another way is the shapiro-wilk normality test:https://www.youtube.com/watch?v=seQokNAEpkM&list=PLqdBkA4Dl3KqNqXe41mOLbpOBLpLZbPI9&index=10

shapiro.test(bodyfat.model$residuals)
#if this test would be significant with a significance level of 0.05, we would have a violation of the normality assumption (H0: there is a normality -> p<=0.05 we reject H0, but for us p-value = 0.1212 on bodyfat.model)
```

```{r Coding res v fit}
res <- resid(bodyfat.model)
plot(fitted(bodyfat.model), res)
abline(0,0)
```

```{r Coding res v leverage and cooks distance}
#outlier detection using ols: https://www.youtube.com/watch?v=EOtXGwUU81w&list=PLqdBkA4Dl3KqNqXe41mOLbpOBLpLZbPI9&index=7

#install.packages("olsrr")
#if you havent installed olsrr, remove commenting above to install.packages("olsrr")
library(olsrr)

bodyfat.model.stud <- rstudent(bodyfat.model)

#plot leverage and outliers
ols_plot_resid_lev(bodyfat.model)

#plot Cook's distance
ols_plot_cooksd_chart(bodyfat.model)

```

```{r Coding testing for constant variance (=homocedasticity)}
#https://www.youtube.com/watch?v=k_oDaBeIaz4&list=PLqdBkA4Dl3KqNqXe41mOLbpOBLpLZbPI9&index=6

ols_test_breusch_pagan(bodyfat.model)
#Prob > Chi2   =    0.4612199  meaning we can not reject the Ho based on significance level 0.05 (we cannot reject the variance is constant)
```

```{r Coding testing the absence of multicollinearity}
#https://www.youtube.com/watch?v=70njB2aqZuU&list=PLqdBkA4Dl3KqNqXe41mOLbpOBLpLZbPI9&index=11

library(car)
vif(bodyfat.model)

#From lecture 7 on multicollinearity: "A VIF above 5 or 10 suggests significant multicollinearity and poor estimation of the associated coefficients". 
#Results show above 10: weight=33.509320, abdomen=11.767073, hip= 14.796520
#Results show above 5: chest= 9.460877, thigh= 7.777865

```










```{r R^2 Coefficient of Determination}
# Get the summary of the model
model_summary <- summary(bodyfat.model)

# Extract R-squared
r_squared <- model_summary$r.squared
adj_r_squared <- model_summary$adj.r.squared

# Print the values
print(paste("R-squared:", r_squared))
print(paste("Adjusted R-squared:", adj_r_squared))
```

```{r An example of a Transformation, albeit we say we don't need transform}
library(MASS)
bodyfat.model <- lm(density ~ age + weight + height + neck + chest + abdomen +
                      hip + thigh + knee + ankle + biceps + forearm + wrist,
                      data = bodyfatmen)

bc <- boxcox(bodyfat.model, lambda = seq(-2, 2, 0.1))
# Identify the lambda with the maximum log-likelihood:
optimal_lambda <- bc$x[which.max(bc$y)]
print(optimal_lambda)

bodyfatmen$density_trans <- if(optimal_lambda == 0) {
  log(bodyfatmen$density)
} else {
  (bodyfatmen$density^optimal_lambda - 1) / optimal_lambda
}
bodyfat_trans_model <- lm(density_trans ~ age + weight + height + neck + chest +
                          abdomen + hip + thigh + knee + ankle + biceps +
                          forearm + wrist, data = bodyfatmen)
model_residuals =bodyfat_trans_model$residuals
hist(model_residuals)
qqnorm(rstudent(bodyfat_trans_model))
qqline(rstudent(bodyfat_trans_model))

```

```{r QQ-plot and Studentized residual vs fitted value plot}
# Create the "plots" folder if it doesn't already exist
if (!dir.exists("plots")) {
  dir.create("plots")
}

### 1. Save the basic residuals plot

# Open a PNG device for the basic plot
png("plots/plotResiduals_basic.png", width = 800, height = 600)

# Compute R-student residuals and create the basic plot
rstudent_residuals <- rstudent(bodyfat.model)
plot(bodyfat.model$fitted.values, rstudent_residuals,
     main = "Fitted Values vs R-student Residuals",
     xlab = "Fitted Values",
     ylab = "R-student Residuals",
     pch = 19, col = "blue")
abline(h = 0, lty = 2, col = "red")

# Close the device so the file is saved
dev.off()


### 2. Save the residuals plot with outliers highlighted

# Open a PNG device for the outlier-highlighted plot
png("plots/plotResiduals_outliers.png", width = 800, height = 600)

# Re-compute R-student residuals (if needed) and identify outliers
rstudent_residuals <- rstudent(bodyfat.model)
outlier_indices <- which(abs(rstudent_residuals) > 2)

# Plot the residuals
plot(bodyfat.model$fitted.values, rstudent_residuals,
     main = "Fitted Values vs R-student Residuals",
     xlab = "Fitted Values",
     ylab = "R-student Residuals",
     pch = 19, col = "blue")

# Add reference lines at 0 and Â±2 (for the outlier threshold)
abline(h = c(0, 2, -2), lty = 2, col = c("red", "darkgray", "darkgray"))

# Highlight outliers in red and add text labels for them
points(bodyfat.model$fitted.values[outlier_indices],
       rstudent_residuals[outlier_indices],
       col = "red", pch = 19, cex = 1.2)
text(bodyfat.model$fitted.values[outlier_indices],
     rstudent_residuals[outlier_indices],
     labels = outlier_indices, pos = 3, cex = 0.7, col = "black")

# Close the device
dev.off()


### 3. Save the QQ plot of R-student residuals

# Open a PNG device for the QQ plot
png("plots/qqPlotResiduals.png", width = 800, height = 600)

# Ensure a single plotting region and produce the QQ plot
par(mfrow = c(1, 1))
qqnorm(rstudent(bodyfat.model))
qqline(rstudent(bodyfat.model))

# Close the device
dev.off()

```

```{r Partial regression plots}
# Load necessary library
library(car)

# Create a directory to store plots
dir.create("partial_regression_Plots", showWarnings = FALSE)

# Manually specify all regressors
predictors <- c("age", "weight", "height", "neck", "chest", "abdomen", 
                "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")

# Save each partial regression plot as a PNG
for (var in predictors) {
  png_filename <- paste0("partial_regression_Plots/", var, "_partial_regression.png")
  png(png_filename, width = 800, height = 600)  # Open PNG device
  
  # Check if variable exists in the model before plotting
  if (var %in% names(coef(bodyfat.model))) {
    avPlots(bodyfat.model, terms = var)  # Generate partial regression plot for the variable
  } else {
    plot.new()
    text(0.5, 0.5, paste("Variable", var, "not in model"), cex = 1.5)
  }
  
  dev.off()  # Close PNG device
}

# Message to confirm
cat("partial regression plots saved in the 'partial_regression_Plots' folder.\n")

```

```{r Partial residual plots}
# Load necessary library
library(car)

# Create a directory to store plots
dir.create("Partial_Residual_Plots", showWarnings = FALSE)

# Manually specify all regressors
predictors <- c("age", "weight", "height", "neck", "chest", "abdomen", 
                "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")

# Save each partial residual plot as a PNG
for (var in predictors) {
  png_filename <- paste0("Partial_Residual_Plots/", var, "_Partial_Residual.png")
  png(png_filename, width = 800, height = 600)  # Open PNG device
  
  # Check if variable exists in the model before plotting
  if (var %in% names(coef(bodyfat.model))) {
    crPlots(bodyfat.model, terms = var)  # Generate partial residual plot for the variable
  } else {
    plot.new()
    text(0.5, 0.5, paste("Variable", var, "not in model"), cex = 1.5)
  }
  
  dev.off()  # Close PNG device
}

# Message to confirm
cat("Partial residual plots saved in the 'Partial_Residual_Plots' folder.\n")

```

```{r Partial residual plots with outliers}
# Load necessary library
library(car)

# Create a new directory for plots
dir.create("Partial_Residual_Plot_Outlier", showWarnings = FALSE)

# Manually specify all regressors
predictors <- c("age", "weight", "height", "neck", "chest", "abdomen", 
                "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")

# Compute studentized residuals for outlier detection
rstudent_residuals <- rstudent(bodyfat.model)
threshold <- 2  # Define threshold for outliers (absolute residual > 2)

# Save each partial residual plot in the new directory
for (var in predictors) {
  png_filename <- paste0("Partial_Residual_Plot_Outlier/", var, "_Partial_Residual.png")
  png(png_filename, width = 800, height = 600)  # Open PNG device
  
  # Check if variable exists in the model before plotting
  if (var %in% names(coef(bodyfat.model))) {
    # Compute partial residuals
    crPlot_data <- residuals(bodyfat.model) + coef(bodyfat.model)[var] * bodyfatmen[[var]]

    # Identify outliers (absolute studentized residual > threshold)
    outlier_indices <- which(abs(rstudent_residuals) > threshold)
    
    # Generate Partial Residual Plot
    plot(bodyfatmen[[var]], crPlot_data, 
         main = paste("Partial Residual Plot:", var), 
         xlab = var, 
         ylab = "Partial Residuals", 
         pch = 19, col = "blue")

    # Add a lowess smooth line to visualize the trend
    lines(lowess(bodyfatmen[[var]], crPlot_data), col = "red", lwd = 2)

    # Highlight outliers in red
    points(bodyfatmen[[var]][outlier_indices], crPlot_data[outlier_indices], 
           col = "red", pch = 19, cex = 1.2)

    # Add text labels for outliers
    text(bodyfatmen[[var]][outlier_indices], crPlot_data[outlier_indices], 
         labels = outlier_indices, pos = 3, cex = 0.7, col = "black")
    
  } else {
    plot.new()
    text(0.5, 0.5, paste("Variable", var, "not in model"), cex = 1.5)
  }
  
  dev.off()  # Close PNG device
}

# Message to confirm
cat("Partial residual plots with outliers saved in 'Partial_Residual_Plot_Outlier' folder.\n")

```




```{r}
library(reshape2)
melted_bodyfatmen <- melt(bodyfatmen)
head(melted_bodyfatmen)

library(ggplot2)
ggplot(data = melted_bodyfatmen, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile()
```



```{r All possible models then best based on BIC (variable selection)}
# Install packages if not already installed
if (!require(leaps)) install.packages("leaps")
library(leaps)

# Use regsubsets to search through all models (nvmax = 13 since we have 13 predictors)
all.subsets <- regsubsets(density ~ age + weight + height + neck + chest + abdomen +
                          hip + thigh + knee + ankle + biceps + forearm + wrist,
                          data = bodyfatmen, nvmax = 13)

# Get a summary of the results
all.subsets.summary <- summary(all.subsets)

# Print available statistics: Adjusted R^2, Mallows' Cp, and BIC
print(names(all.subsets.summary))
# Typically, you'll see:
#   - all.subsets.summary$rsq         : R-squared
#   - all.subsets.summary$adjr2       : Adjusted R-squared
#   - all.subsets.summary$cp          : Mallows' Cp
#   - all.subsets.summary$bic         : BIC

# Identify the best model according to each criterion:
best.adjr2  <- which.max(all.subsets.summary$adjr2)
best.cp     <- which.min(all.subsets.summary$cp)
best.bic    <- which.min(all.subsets.summary$bic)
# Now, compute AIC for each model.
# For a linear model, AIC can be approximated as:
#    AIC = n * log(RSS/n) + 2K
# where n = number of observations, RSS = residual sum of squares, and K = number of parameters (predictors + intercept).

n <- nrow(bodyfatmen)  # number of observations

# Extract RSS from the summary
rss <- all.subsets.summary$rss

# Determine the number of predictors included in each model.
# all.subsets.summary$which is a logical matrix where rows correspond to models.
# The first column is for the intercept (which is always TRUE). We subtract 1 to count only the predictors.
num_pred <- apply(all.subsets.summary$which, 1, sum) - 1  
K <- num_pred + 1  # K = number of predictors + 1 for the intercept

# Compute AIC for each model
AIC_values <- n * log(rss / n) + 2 * K

# Identify the best model based on AIC (lowest AIC)
best.aic <- which.min(AIC_values)

# Print the indices of the best models according to each criterion
cat("Best model by adjusted R^2: ", best.adjr2, "\n")
cat("Best model by Mallows' Cp: ", best.cp, "\n")
cat("Best model by BIC: ", best.bic, "\n")
cat("Best model by AIC: ", best.aic, "\n")

# Plot Adjusted R^2, Mallows' Cp, and BIC against the number of predictors

par(mfrow = c(1,3))

plot(all.subsets.summary$adjr2, xlab = "Number of Predictors", 
     ylab = "Adjusted R^2", type = "b", main = "Adjusted R^2")
points(best.adjr2, all.subsets.summary$adjr2[best.adjr2], col = "red", pch = 19)

plot(all.subsets.summary$cp, xlab = "Number of Predictors", 
     ylab = "Mallows' Cp", type = "b", main = "Mallows' Cp")
points(best.cp, all.subsets.summary$cp[best.cp], col = "red", pch = 19)

plot(all.subsets.summary$bic, xlab = "Number of Predictors", 
     ylab = "BIC", type = "b", main = "BIC")
points(best.bic, all.subsets.summary$bic[best.bic], col = "red", pch = 19)
# AIC Plot
plot(AIC_values, xlab = "Number of Predictors", ylab = "AIC", 
     type = "b", main = "AIC")
points(best.aic, AIC_values[best.aic], col = "red", pch = 19)

# Install caret if necessary
if (!require(caret)) install.packages("caret")
library(caret)

set.seed(123)  # For reproducibility

# Set up 10-fold cross-validation
train.control <- trainControl(method = "cv", number = 10)

# Use caret's train function with method "leapSeq" to search over number of predictors (nvmax from 1 to 13)
cv.model <- train(density ~ age + weight + height + neck + chest + abdomen +
                  hip + thigh + knee + ankle + biceps + forearm + wrist,
                  data = bodyfatmen,
                  method = "leapSeq",
                  tuneGrid = data.frame(nvmax = 1:13),
                  trControl = train.control)

# View cross-validation results
print(cv.model)
plot(cv.model)

# Get the coefficients for the model with the lowest BIC
best.model.bic <- coef(all.subsets, best.bic)
cat("Best model by BIC:\n")
print(best.model.bic)

# Get the coefficients for the model with the lowest AIC
best.model.aic <- coef(all.subsets, best.aic)
cat("\nBest model by AIC:\n")
print(best.model.aic)

# Get the coefficients for the model with the highest Adjusted R^2
best.model.adjr2 <- coef(all.subsets, best.adjr2)
cat("\nBest model by Adjusted R^2:\n")
print(best.model.adjr2)

# Get the coefficients for the model with the lowest Mallows' Cp
best.model.cp <- coef(all.subsets, best.cp)
cat("\nBest model by Mallows' Cp:\n")
print(best.model.cp)


```
```{r Cross validation - Adjusted R2, MSE}
# If not installed, install the 'leaps' package
#if(!require(leaps)) install.packages("leaps")
library(leaps)

# Example: we assume 'bodyfatmen' is a data frame with columns:
#   density, age, weight, height, neck, chest, abdomen,
#   hip, thigh, knee, ankle, biceps, forearm, wrist

# Set a seed for reproducibility
set.seed(1)

# Number of folds for cross-validation
K <- 10

# Create a vector of fold assignments (randomly 1 through K)
folds <- sample(1:K, nrow(bodyfatmen), replace = TRUE)


# Matrices to store MSE and adjusted R^2 for each fold (row) and model size (column)
cv.MSE <- matrix(NA, nrow = K, ncol = 13)
cv.adjR2 <- matrix(NA, nrow = K, ncol = 13)

# Cross-validation loop
for(k in 1:K) {
  # Split data into training and test sets
  train_data <- bodyfatmen[folds != k, ]
  test_data  <- bodyfatmen[folds == k, ]
  
  # Fit all subsets on the training data (up to 13 predictors)
  best_subset_fit <- regsubsets(
    density ~ age + weight + height + neck + chest + abdomen +
      hip + thigh + knee + ankle + biceps + forearm + wrist,
    data = train_data,
    nvmax = 13
  )
  
  # Model matrix for the test set
  test_mat <- model.matrix(
    density ~ age + weight + height + neck + chest + abdomen +
      hip + thigh + knee + ankle + biceps + forearm + wrist,
    data = test_data
  )
  
  # Evaluate each model size from 1 to 13
  for(size in 1:13) {
    # Extract the coefficients for the 'size'-predictor model
    coefs <- coef(best_subset_fit, id = size)
    
    # The columns in 'test_mat' must match the names in 'coefs'
    # Multiply to get predictions on the test set
    pred <- test_mat[, names(coefs)] %*% coefs
    
    # ---- 2A. Compute Test MSE ----
    residuals <- test_data$density - pred
    cv.MSE[k, size] <- mean(residuals^2)
    
    # ---- 2B. Compute Test Adjusted R^2 ----
    # We'll define a test-based Adjusted R^2 as:
    #    1 - (SSE / (n_test - p - 1)) / (SST / (n_test - 1))
    # where p is the number of predictors (excluding intercept),
    # SSE is sum of squared errors on test set,
    # and SST is sum of squared deviations from the test set mean.
    
    n_test <- nrow(test_data)
    p <- size  # number of predictors in the model
    SSE <- sum(residuals^2)
    SST <- sum((test_data$density - mean(test_data$density))^2)
    
    # Avoid negative or undefined values if size ~ n_test
    if(n_test > p + 1) {
      test_adjR2 <- 1 - ((SSE / (n_test - p - 1)) / (SST / (n_test - 1)))
    } else {
      test_adjR2 <- NA
    }
    
    cv.adjR2[k, size] <- test_adjR2
  }
}


# Average test MSE across folds for each model size
mean_MSE <- apply(cv.MSE, 2, mean, na.rm = TRUE)

# Average test-based adjusted R^2 across folds for each model size
mean_adjR2 <- apply(cv.adjR2, 2, mean, na.rm = TRUE)

# Find the model size that gives the lowest average test MSE
best_size_MSE <- which.min(mean_MSE)
# Find the model size that gives the highest average test-based adjusted R^2
best_size_adjR2 <- which.max(mean_adjR2)

cat("Best model size by cross-validated test MSE:", best_size_MSE, "\n")
cat("Best model size by cross-validated test adjusted R^2:", best_size_adjR2, "\n")

# Print the actual values for reference
cat("\nMean MSE for each model size:\n")
print(mean_MSE)
cat("\nMean Adjusted R^2 for each model size:\n")
print(mean_adjR2)


# Refit best-subset with the entire data, up to 13 predictors
final_fit <- regsubsets(
  density ~ age + weight + height + neck + chest + abdomen +
    hip + thigh + knee + ankle + biceps + forearm + wrist,
  data = bodyfatmen,
  nvmax = 13
)

# Extract the coefficients for the best sizes
cat("\nCoefficients for best size (by MSE):\n")
print(coef(final_fit, id = best_size_MSE))

cat("\nCoefficients for best size (by Adj R^2):\n")
print(coef(final_fit, id = best_size_adjR2))

```

```{r}
# Load required packages
if (!require(leaps)) install.packages("leaps")
library(leaps)
if (!require(caret)) install.packages("caret")
library(caret)
if (!require(boot)) install.packages("boot")
library(boot)

# (Assuming the previous code has been run to compute all.subsets and best.bic, etc.)
# Get the coefficients for the best model by BIC
best.model.bic <- coef(all.subsets, best.bic)
cat("Best model by BIC:\n")
print(best.model.bic)

# Identify the predictors in the best model (exclude intercept)
predictors <- names(best.model.bic)[-1]

# Construct the formula for the selected model
formula_str <- paste("density ~", paste(predictors, collapse = " + "))
model_formula <- as.formula(formula_str)
cat("\nModel formula based on best BIC model:\n")
print(model_formula)

# Fit the linear model on the full dataset for reference
lm_fit <- lm(model_formula, data = bodyfatmen)
summary(lm_fit)

# Define a bootstrap function to compute coefficient estimates
boot_fn <- function(data, indices) {
  # Resample the data with indices provided by boot()
  boot_data <- data[indices, ]
  # Fit the linear model on the bootstrap sample
  fit <- lm(model_formula, data = boot_data)
  # Return the coefficients
  return(coef(fit))
}

set.seed(123)  # For reproducibility

# Run bootstrap with 1000 replications
boot_results <- boot(data = bodyfatmen, statistic = boot_fn, R = 1000)
print(boot_results)

# Obtain bootstrap confidence intervals (percentile method) for each coefficient
cat("\nBootstrap Percentile Confidence Intervals:\n")
boot_ci_list <- list()

for (i in 1:length(boot_results$t0)) {
  coef_name <- names(boot_results$t0)[i]
  # Compute the percentile CI for the ith coefficient
  ci <- boot.ci(boot_results, type = "perc", index = i)
  boot_ci_list[[coef_name]] <- ci$perc[4:5]
  cat(sprintf("%s: [%.4f, %.4f]\n", coef_name, ci$perc[4], ci$perc[5]))
}

# You now have the bootstrap-based confidence intervals for the regression coefficients

```




```{r Multicollinearity}
# Load necessary libraries
# install.packages("GGally")

library(car)    # For VIF
library(GGally) # For ggpairs

# Fit linear model
bodyfat.model <- lm(density ~ age + weight + height + neck + chest + abdomen + hip + thigh + knee + ankle + biceps + forearm + wrist, data = bodyfatmen)


# (a) Correlation matrix to detect multicollinearity
X <- model.matrix(bodyfat.model)
XtX <- cor(X[,-1])  # Compute correlation matrix of predictors

# Check for strong correlations
print(XtX)

# Visualizing correlations between selected variables
ggpairs(data = bodyfatmen[, c("age", "abdomen", "hip")])  # Change variables as needed

# (b) Variance Inflation Factor (VIF)
vif_values <- vif(bodyfat.model)  # Compute VIF
print(vif_values)  # VIF > 10 indicates multicollinearity

# Compute inverse of XtX
XtX_inv <- solve(XtX)
print(XtX_inv)  # Compare diagonal values with VIFs

# Condition number to check for multicollinearity
bodyfat.eigen <- eigen(XtX)
condition_number <- max(bodyfat.eigen$values) / min(bodyfat.eigen$values)
print(condition_number)  # Condition number > 100 suggests multicollinearity

```

```{r Correlation matrix heatmap}
# Load necessary libraries
library(ggplot2)
library(reshape2)  # For reshaping data

# Compute correlation matrix
XtX <- cor(X[,-1])

# Convert to long format for ggplot
XtX_melted <- melt(XtX)

# Plot heatmap with color gradient
ggplot(data = XtX_melted, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Correlation Matrix Heatmap", fill = "Correlation")

```

```{r VIF and Eigenvalue}
# Load necessary library
library(ggplot2)

# Compute Variance Inflation Factors
vif_values <- vif(bodyfat.model)

# Convert to data frame for ggplot
vif_df <- data.frame(Variable = names(vif_values), VIF = vif_values)

ggplot(vif_df, aes(x = reorder(Variable, VIF), y = VIF, fill = VIF)) +
  geom_bar(stat = "identity") +
  geom_hline(yintercept = 5, linetype = "dashed", color = "blue") +
  geom_hline(yintercept = 10, linetype = "dashed", color = "red") +
  scale_fill_gradient(low = "green", high = "red") +
  theme_minimal() +
  coord_flip() +
  labs(title = "Variance Inflation Factor (VIF) for Predictors",
       x = "Predictor Variables",
       y = "VIF Value",
       fill = "VIF")


# Compute eigenvalues of XtX (correlation matrix)
bodyfat.eigen <- eigen(XtX)

# Convert to data frame
eigen_df <- data.frame(Eigenvalue = bodyfat.eigen$values,
                       Index = seq_along(bodyfat.eigen$values))

# Compute condition number
condition_number <- max(eigen_df$Eigenvalue) / min(eigen_df$Eigenvalue)

# Plot eigenvalues
ggplot(eigen_df, aes(x = Index, y = Eigenvalue, fill = Eigenvalue)) +
  geom_bar(stat = "identity") +
  scale_fill_gradient(low = "blue", high = "orange") +
  theme_minimal() +
  labs(title = paste("Eigenvalues of XtX (Condition Number =", round(condition_number, 2), ")"),
       x = "Index",
       y = "Eigenvalue",
       fill = "Eigenvalue")


```


```{r Best Subset Regression for Density Prediction}
# Load necessary libraries
library(car)    # For multicollinearity diagnostics
library(leaps)  # For best subset selection
library(glmnet) # For Ridge and Lasso
library(boot)   # For cross-validation
library(MASS)   # For stepwise selection

# Define dependent and independent variables
y <- bodyfatmen$density
X <- bodyfatmen[, !(names(bodyfatmen) %in% c("density"))]

# Compute Variance Inflation Factor (VIF)
vif_results <- vif(lm(y ~ ., data=bodyfatmen))
print(vif_results)

# Perform best subset selection
best_subset <- regsubsets(density ~ ., data=bodyfatmen, nvmax=ncol(X))

# Get summary of best models
best_summary <- summary(best_subset)

# Display model selection criteria
best_models <- data.frame(
  Num_Variables = 1:length(best_summary$rsq),
  Adjusted_R2 = best_summary$adjr2,
  Cp = best_summary$cp,
  BIC = best_summary$bic
)

print(best_models)


```


```{r Some help}
# ============================
# 1. LOAD LIBRARIES AND DATA
# ============================

# Load necessary libraries
library(car)       # For VIF, diagnostic plots, etc.
library(MASS)      # For stepAIC and BoxâCox transformations
library(leaps)     # For all subsets regression (regsubsets)
library(boot)      # For cross-validation and bootstrapping
library(ggplot2)   # For plotting
library(reshape2)  # For reshaping correlation matrices for heatmaps

# Load your data (update the file path as needed)
bodyfatmen <- read.csv("bodyfatmen.csv", header = TRUE)

# ============================
# 2. MULTICOLLINEARITY DIAGNOSTICS
# ============================

# Fit the full model using all predictors
full_model <- lm(density ~ age + weight + height + neck + chest + abdomen +
                   hip + thigh + knee + ankle + biceps + forearm + wrist,
                 data = bodyfatmen)

# (a) Correlation Matrix of Predictors (excluding the response)
predictors <- bodyfatmen[, setdiff(names(bodyfatmen), "density")]
cor_matrix <- cor(predictors)
print("Correlation matrix of predictors:")
print(cor_matrix)

# Plot a heatmap of the correlation matrix
melted_cor <- melt(cor_matrix)
ggplot(data = melted_cor, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle("Correlation Matrix Heatmap")

# (b) Variance Inflation Factors (VIF)
vif_values <- vif(full_model)
print("Variance Inflation Factors (VIF):")
print(vif_values)

# (c) Eigenvalues and Condition Number for XtX
X <- model.matrix(full_model)
XtX <- t(X) %*% X
eigen_vals <- eigen(XtX)$values
condition_number <- max(eigen_vals) / min(eigen_vals)
print("Eigenvalues of XtX:")
print(eigen_vals)
print(paste("Condition Number:", round(condition_number, 2)))
# Note: A condition number > 100 may indicate potential multicollinearity.

# ============================
# 3. VARIABLE SELECTION METHODS
# ============================

# (a) All Possible Regressions using 'regsubsets'
all_subsets <- regsubsets(density ~ age + weight + height + neck + chest +
                            abdomen + hip + thigh + knee + ankle + biceps +
                            forearm + wrist, data = bodyfatmen, nvmax = 13)
all_subsets_summary <- summary(all_subsets)
print("All subsets regression summary:")
print(all_subsets_summary)
# Inspect criteria such as Adjusted R^2, Mallowsâ Cp, and BIC from the summary
# e.g., all_subsets_summary$adjr2, all_subsets_summary$cp, all_subsets_summary$bic

# (b) Forward/Backward Elimination using stepAIC
step_model <- stepAIC(full_model, direction = "both", trace = FALSE)
print("Stepwise Selection Model Summary:")
summary(step_model)

# ============================
# 4. CROSS-VALIDATION FOR MODEL EVALUATION
# ============================

# Partition the data into a training set (70%) and a test set (30%)
set.seed(123)
n <- nrow(bodyfatmen)
train_indices <- sample(1:n, size = floor(0.7 * n))
train_data <- bodyfatmen[train_indices, ]
test_data <- bodyfatmen[-train_indices, ]

# Suppose variable selection (and diagnostics) led to the following final model:
final_model <- lm(density ~ weight + height + abdomen + I(abdomen^2) + wrist,
                  data = train_data)
print("Final Model Summary:")
summary(final_model)

# (a) Predict on the Test Set and Calculate Test MSE
predictions <- predict(final_model, newdata = test_data)
test_MSE <- mean((test_data$density - predictions)^2)
print(paste("Test Set MSE:", round(test_MSE, 4)))

# (b) Calculate Adjusted R^2 on the Test Set (manual calculation)
SSE <- sum((test_data$density - predictions)^2)
SST <- sum((test_data$density - mean(train_data$density))^2)
R2 <- 1 - SSE / SST
n_test <- nrow(test_data)
p_final <- length(coef(final_model)) - 1  # Number of predictors
adj_R2 <- 1 - ((1 - R2) * (n_test - 1) / (n_test - p_final - 1))
print(paste("Test Set Adjusted R^2:", round(adj_R2, 4)))

# (c) Alternatively, perform 10-fold cross-validation using cv.glm
cv_results <- cv.glm(data = bodyfatmen, glmfit = final_model, K = 10)
print("10-fold Cross-Validation MSE (cv.glm):")
print(cv_results$delta[1])  # The first value is the raw cross-validation estimate

# ============================
# 5. BOOTSTRAP PROCEDURES FOR MODEL ASSESSMENT
# ============================

# (a) Bootstrap to Generate Confidence Intervals for Regression Coefficients
# using the percentile method (based on bootstrapped residuals)

set.seed(123)
n_boot <- 1000  # Number of bootstrap samples
boot_coefs <- matrix(NA, n_boot, length(coef(final_model)))
colnames(boot_coefs) <- names(coef(final_model))

# Bootstrap loop: resample residuals and refit the model
for (i in 1:n_boot) {
  # Resample residuals with replacement from the final model
  boot_residuals <- sample(resid(final_model), replace = TRUE)
  # Generate new response: fitted values + resampled residuals
  boot_y <- fitted(final_model) + boot_residuals
  # Refit the final model using the bootstrapped response
  boot_model <- lm(boot_y ~ weight + height + abdomen + I(abdomen^2) + wrist,
                   data = train_data)
  boot_coefs[i, ] <- coef(boot_model)
}

# Calculate 95% bootstrap confidence intervals (percentile method)
boot_ci <- apply(boot_coefs, 2, quantile, probs = c(0.025, 0.975))
print("Bootstrap-based 95% Confidence Intervals for Regression Coefficients:")
print(boot_ci)

# ============================
# 6. FINAL MODEL SPECIFICATION
# ============================
# Our final selected model is:
#   density ~ weight + height + abdomen + I(abdomen^2) + wrist
#
# This model was chosen based on diagnostics (e.g., residual analysis, VIFs),
# variable selection (using all-subsets and stepwise elimination), and cross-validation
# which indicated favorable predictive performance (i.e., low MSE and high adjusted R^2).

print("Final Model Specification:")
print(summary(final_model))

```
```{r Quick overview analysis}
full_model <- lm(density ~ ., data = bodyfatmen)
summary(full_model)
par(mfrow = c(1, 1))  # Arrange diagnostic plots in a 2x2 grid
plot(full_model)

```
```{r Summary Statistics, makes into Latex code}
# Install and load xtable
install.packages("xtable")  # Install if not already installed
library(xtable)

# Get the summary
summary_stats <- summary(bodyfatmen)

# Convert to a LaTeX table
latex_table <- xtable(summary_stats)

# Print LaTeX code
print(latex_table, type = "latex")


```
```{r Other}
cor(bodyfatmen)
pairs(bodyfatmen)
library(MASS)
stepwise_model <- stepAIC(full_model, direction = "both")
summary(stepwise_model)
library(leaps)
best_subset <- regsubsets(density ~ ., data = bodyfatmen, nbest = 5)
summary(best_subset)
# Create a new data point
new_data <- data.frame(age = 25, weight = 175, height = 70, neck = 36, chest = 95, abdomen = 90, hip = 100, thigh = 60, knee= 100, ankle = 100, biceps= 100, forearm= 100, wrist=100)

# Predict with confidence intervals
predict(full_model, newdata = new_data, interval = "confidence")
library(boot)
cv_error <- cv.glm(bodyfatmen, full_model, K = 10)
cv_error$delta

```
